[{"C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\reportWebVitals.js":"1","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\App.js":"2","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\pages\\Record\\Record.js":"3","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\index.js":"4","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\pages\\Record\\utils.js":"5","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\pages\\Record\\history.js":"6","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\pages\\Record\\DemoRecord.js":"7","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\components\\VideoSelector.js":"8","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\components\\poseUtils.js":"9","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\components\\Video.js":"10","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\components\\demo_util.js":"11","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\dataset\\index.js":"12","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\MoreRecord.js":"13"},{"size":362,"mtime":1610817124884,"results":"14","hashOfConfig":"15"},{"size":760,"mtime":1610929688592,"results":"16","hashOfConfig":"15"},{"size":3663,"mtime":1610903907762,"results":"17","hashOfConfig":"15"},{"size":500,"mtime":1610817124884,"results":"18","hashOfConfig":"15"},{"size":7401,"mtime":1610900341520,"results":"19","hashOfConfig":"15"},{"size":86,"mtime":1610862211147,"results":"20","hashOfConfig":"15"},{"size":15377,"mtime":1610873965349,"results":"21","hashOfConfig":"15"},{"size":2612,"mtime":1610929975959,"results":"22","hashOfConfig":"15"},{"size":7083,"mtime":1610928270386,"results":"23","hashOfConfig":"15"},{"size":1905,"mtime":1559182462000,"results":"24","hashOfConfig":"15"},{"size":5348,"mtime":1610915080353,"results":"25","hashOfConfig":"15"},{"size":401,"mtime":1610916921409,"results":"26","hashOfConfig":"15"},{"size":376,"mtime":1610930019487,"results":"27","hashOfConfig":"15"},{"filePath":"28","messages":"29","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"x3jplo",{"filePath":"30","messages":"31","errorCount":0,"warningCount":10,"fixableErrorCount":0,"fixableWarningCount":0,"source":"32"},{"filePath":"33","messages":"34","errorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"35"},{"filePath":"36","messages":"37","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"38"},{"filePath":"39","messages":"40","errorCount":0,"warningCount":5,"fixableErrorCount":0,"fixableWarningCount":0,"source":"41"},{"filePath":"42","messages":"43","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"44","messages":"45","errorCount":0,"warningCount":21,"fixableErrorCount":0,"fixableWarningCount":0,"source":"46"},{"filePath":"47","messages":"48","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"49","messages":"50","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"51","messages":"52","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"53","messages":"54","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"55","messages":"56","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"57","messages":"58","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\reportWebVitals.js",[],"C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\App.js",["59","60","61","62","63","64","65","66","67","68"],"import logo from './logo.svg';\nimport './App.css';\nimport {\n  BrowserRouter as Router,\n  Switch,\n  Route,\n  Link,\n  useRouteMatch,\n  useParams\n} from \"react-router-dom\";\nimport Record from './pages/Record/Record';\nimport React, { useRef } from \"react\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as bodyPix from \"@tensorflow-models/body-pix\";\nimport Webcam from \"react-webcam\";\nimport \"./App.css\";\n/*import DemoRecord from './pages/Record/DemoRecord';*/\nimport MoreRecord from './MoreRecord';\n\nconsole.log(MoreRecord);\nfunction App() {\n  return (\n        <Router>\n           <div className=\"App\">\n            \n            <Route path = \"/record\" component={MoreRecord}/>\n           </div>\n           </Router>\n      \n      \n  );\n}\n\n\n\nexport default App;\n","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\pages\\Record\\Record.js",["69","70","71"],"import React, { useRef, Component } from \"react\";\r\n/* import \"./App.css\"; */\r\nimport * as tf from \"@tensorflow/tfjs\";\r\nimport * as posenet from \"@tensorflow-models/posenet\";\r\nimport Webcam from \"react-webcam\";\r\nimport { drawKeypoints, drawSkeleton } from \"./utils\";\r\n/* import {drawBoundingBox, drawKeypoints, drawSkeleton, isMobile, toggleLoadingUI, global_zero} from './demo-util'; */\r\n\r\nimport Button from '@material-ui/core/Button';\r\nimport ButtonGroup from '@material-ui/core/ButtonGroup';\r\nimport history from './history';\r\nimport ReactTimerStopwatch from 'react-stopwatch-timer';\r\nimport \"./Record.css\";\r\n\r\n\r\n\r\n\r\nfunction Record() {\r\n  const webcamRef = useRef(null);\r\n  const canvasRef = useRef(null);\r\n  var rep_count = 0;\r\n\r\n  //  Load posenet\r\n  const runPosenet = async () => {\r\n    const net = await posenet.load({\r\n      inputResolution: { width: 640, height: 480 },\r\n      scale: 0.8,\r\n    });\r\n    //\r\n    setInterval(() => {\r\n      detect(net);\r\n    }, 100);\r\n  };\r\n\r\n  const detect = async (net) => {\r\n    if (\r\n      typeof webcamRef.current !== \"undefined\" &&\r\n      webcamRef.current !== null &&\r\n      webcamRef.current.video.readyState === 4\r\n    ) {\r\n      // Get Video Properties\r\n      const video = webcamRef.current.video;\r\n      const videoWidth = webcamRef.current.video.videoWidth;\r\n      const videoHeight = webcamRef.current.video.videoHeight;\r\n\r\n      // Set video width\r\n      webcamRef.current.video.width = videoWidth;\r\n      webcamRef.current.video.height = videoHeight;\r\n\r\n      // Make Detections\r\n      const pose = await net.estimateSinglePose(video);\r\n      console.log(pose);\r\n\r\n      drawCanvas(pose, video, videoWidth, videoHeight, canvasRef);\r\n\r\n     \r\n    }\r\n    \r\n  };\r\n\r\n \r\n  const drawCanvas = (pose, video, videoWidth, videoHeight, canvas) => {\r\n    const ctx = canvas.current.getContext(\"2d\");\r\n    canvas.current.width = videoWidth;\r\n    canvas.current.height = videoHeight;\r\n   \r\n        \r\n        rep_count = rep_count + drawKeypoints((pose[\"keypoints\"], 0.9, ctx));\r\n        console.log(\"YERRR:\" + rep_count);\r\n        \r\n\r\n\r\n    drawKeypoints(pose[\"keypoints\"], 0.9, ctx);\r\n    drawSkeleton(pose[\"keypoints\"], 0.7, ctx);\r\n  };\r\n\r\n  runPosenet();\r\n\r\n  return (\r\n    <div className=\"App\">\r\n      <header className=\"App-header\">\r\n        <Webcam\r\n          ref={webcamRef}\r\n          style={{\r\n            position: \"absolute\",\r\n            marginLeft: \"auto\",\r\n            marginRight: \"auto\",\r\n            marginTop: -70,\r\n            left: 0,\r\n            right: 0,\r\n            textAlign: \"center\",\r\n            zindex: 9,\r\n            width: 640,\r\n            height: 480,\r\n          }}\r\n        />\r\n\r\n        <canvas\r\n          ref={canvasRef}\r\n          style={{\r\n            position: \"absolute\",\r\n            marginLeft: \"auto\",\r\n            marginRight: \"auto\",\r\n            marginTop: -70,\r\n            left: 0,\r\n            right: 0,\r\n            textAlign: \"center\",\r\n            zindex: 9,\r\n            width: 640,\r\n            height: 480,\r\n          }}\r\n        />\r\n        \r\n       <div id = \"end-workout\">\r\n           <h2 id=\"jacks\"> Jumping Jacks: --</h2>\r\n         <form>\r\n         <ButtonGroup color=\"secondary\" aria-label=\"contained primary button group\">\r\n            <Button variant=\"contained\" color=\"secondary\">Start Workout</Button>\r\n            <Button variant=\"contained\" color=\"secondary\" onClick={() => history.push('/')} style={{maxWidth: '60%', maxHeight: '45%', minWidth: '60%', minHeight: '45%'}}>End Workout</Button>\r\n\r\n        </ButtonGroup>            \r\n          </form>\r\n          </div>\r\n         \r\n      </header>\r\n     \r\n    </div>\r\n  );\r\n}\r\n\r\nexport default Record;","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\index.js",[],["72","73"],"C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\pages\\Record\\utils.js",["74","75","76","77","78"],"/*\r\n * @license\r\n * Copyright 2019 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * https://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport * as posenet from \"@tensorflow-models/posenet\";\r\nimport * as tf from \"@tensorflow/tfjs\";\r\n\r\nconst color = \"aqua\";\r\nconst boundingBoxColor = \"red\";\r\nconst lineWidth = 2;\r\nvar prev = 0;\r\n\r\nexport const tryResNetButtonName = \"tryResNetButton\";\r\nexport const tryResNetButtonText = \"[New] Try ResNet50\";\r\nconst tryResNetButtonTextCss = \"width:100%;text-decoration:underline;\";\r\nconst tryResNetButtonBackgroundCss = \"background:#e61d5f;\";\r\n\r\nfunction isAndroid() {\r\n  return /Android/i.test(navigator.userAgent);\r\n}\r\n\r\nfunction isiOS() {\r\n  return /iPhone|iPad|iPod/i.test(navigator.userAgent);\r\n}\r\n\r\nexport function isMobile() {\r\n  return isAndroid() || isiOS();\r\n}\r\n\r\nfunction setDatGuiPropertyCss(propertyText, liCssString, spanCssString = \"\") {\r\n  var spans = document.getElementsByClassName(\"property-name\");\r\n  for (var i = 0; i < spans.length; i++) {\r\n    var text = spans[i].textContent || spans[i].innerText;\r\n    if (text == propertyText) {\r\n      spans[i].parentNode.parentNode.style = liCssString;\r\n      if (spanCssString !== \"\") {\r\n        spans[i].style = spanCssString;\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\nexport function updateTryResNetButtonDatGuiCss() {\r\n  setDatGuiPropertyCss(\r\n    tryResNetButtonText,\r\n    tryResNetButtonBackgroundCss,\r\n    tryResNetButtonTextCss\r\n  );\r\n}\r\n\r\n/**\r\n * Toggles between the loading UI and the main canvas UI.\r\n */\r\nexport function toggleLoadingUI(\r\n  showLoadingUI,\r\n  loadingDivId = \"loading\",\r\n  mainDivId = \"main\"\r\n) {\r\n  if (showLoadingUI) {\r\n    document.getElementById(loadingDivId).style.display = \"block\";\r\n    document.getElementById(mainDivId).style.display = \"none\";\r\n  } else {\r\n    document.getElementById(loadingDivId).style.display = \"none\";\r\n    document.getElementById(mainDivId).style.display = \"block\";\r\n  }\r\n}\r\n\r\nfunction toTuple({ y, x }) {\r\n  return [y, x];\r\n}\r\n\r\nexport function drawPoint(ctx, y, x, r, color) {\r\n  ctx.beginPath();\r\n  ctx.arc(x, y, r, 0, 2 * Math.PI);\r\n  ctx.fillStyle = color;\r\n  ctx.fill();\r\n}\r\n\r\n/**\r\n * Draws a line on a canvas, i.e. a joint\r\n */\r\nexport function drawSegment([ay, ax], [by, bx], color, scale, ctx) {\r\n  ctx.beginPath();\r\n  ctx.moveTo(ax * scale, ay * scale);\r\n  ctx.lineTo(bx * scale, by * scale);\r\n  ctx.lineWidth = lineWidth;\r\n  ctx.strokeStyle = color;\r\n  ctx.stroke();\r\n}\r\n\r\n/**\r\n * Draws a pose skeleton by looking up all adjacent keypoints/joints\r\n */\r\nexport function drawSkeleton(keypoints, minConfidence, ctx, scale = 1) {\r\n  const adjacentKeyPoints = posenet.getAdjacentKeyPoints(\r\n    keypoints,\r\n    minConfidence\r\n  );\r\n\r\n  adjacentKeyPoints.forEach((keypoints) => {\r\n    drawSegment(\r\n      toTuple(keypoints[0].position),\r\n      toTuple(keypoints[1].position),\r\n      color,\r\n      scale,\r\n      ctx\r\n    );\r\n  });\r\n}\r\n\r\n/**\r\n * Draw pose keypoints onto a canvas\r\n */\r\nexport function drawKeypoints(keypoints, minConfidence, ctx, scale = 1) {\r\n  for (let i = 0; i < keypoints.length; i++) {\r\n    const keypoint = keypoints[i];\r\n\r\n    if (keypoint.score < minConfidence) {\r\n      continue;\r\n    }\r\n\r\n    const { y, x } = keypoint.position;\r\n    drawPoint(ctx, y * scale, x * scale, 3, color);\r\n  }\r\n}\r\n\r\n/**\r\n * Draw the bounding box of a pose. For example, for a whole person standing\r\n * in an image, the bounding box will begin at the nose and extend to one of\r\n * ankles\r\n */\r\nexport function drawBoundingBox(keypoints, ctx) {\r\n  const boundingBox = posenet.getBoundingBox(keypoints);\r\n\r\n  ctx.rect(\r\n    boundingBox.minX,\r\n    boundingBox.minY,\r\n    boundingBox.maxX - boundingBox.minX,\r\n    boundingBox.maxY - boundingBox.minY\r\n  );\r\n\r\n  ctx.strokeStyle = boundingBoxColor;\r\n  ctx.stroke();\r\n}\r\n\r\n/**\r\n * Converts an arary of pixel data into an ImageData object\r\n */\r\nexport async function renderToCanvas(a, ctx) {\r\n  const [height, width] = a.shape;\r\n  const imageData = new ImageData(width, height);\r\n\r\n  const data = await a.data();\r\n\r\n  for (let i = 0; i < height * width; ++i) {\r\n    const j = i * 4;\r\n    const k = i * 3;\r\n\r\n    imageData.data[j + 0] = data[k + 0];\r\n    imageData.data[j + 1] = data[k + 1];\r\n    imageData.data[j + 2] = data[k + 2];\r\n    imageData.data[j + 3] = 255;\r\n  }\r\n\r\n  ctx.putImageData(imageData, 0, 0);\r\n}\r\n\r\n/**\r\n * Draw an image on a canvas\r\n */\r\nexport function renderImageToCanvas(image, size, canvas) {\r\n  canvas.width = size[0];\r\n  canvas.height = size[1];\r\n  const ctx = canvas.getContext(\"2d\");\r\n\r\n  ctx.drawImage(image, 0, 0);\r\n}\r\n\r\n/**\r\n * Draw heatmap values, one of the model outputs, on to the canvas\r\n * Read our blog post for a description of PoseNet's heatmap outputs\r\n * https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5\r\n */\r\nexport function drawHeatMapValues(heatMapValues, outputStride, canvas) {\r\n  const ctx = canvas.getContext(\"2d\");\r\n  const radius = 5;\r\n  const scaledValues = heatMapValues.mul(tf.scalar(outputStride, \"int32\"));\r\n\r\n  drawPoints(ctx, scaledValues, radius, color);\r\n}\r\nexport function global_zero(){\r\n    prev = 0;\r\n  }\r\nexport function jumping_jack_calc(keypoints, minConfidence, ctx, wko_started){\r\n    const right_ident = keypoints[10].score > minConfidence && keypoints[14].score > minConfidence && keypoints[16].score > minConfidence;\r\n    const left_ident = keypoints[9].score > minConfidence && keypoints[13].score > minConfidence && keypoints[15].score > minConfidence;\r\n  \r\n    if (right_ident && left_ident && wko_started == 1) {\r\n      const wrist_diff = Math.abs(keypoints[10].position.x - keypoints[9].position.x);\r\n      console.log('wrist_diff: ', wrist_diff);\r\n      const knee_diff = Math.abs(keypoints[14].position.x - keypoints[13].position.x);\r\n      console.log('knee_diff: ', knee_diff);\r\n      const ankle_diff = Math.abs(keypoints[16].position.x - keypoints[15].position.x)\r\n      console.log('ankle_diff: ', ankle_diff);\r\n  \r\n      const sum = wrist_diff + ankle_diff;\r\n      console.log('sum: ', sum);\r\n      if (sum <= 55){\r\n        if (prev == 0){\r\n          prev = -1;\r\n          return 0;\r\n        }\r\n        else if (prev == 1){\r\n          prev = -1;\r\n          return 1;\r\n        }\r\n      }\r\n      else if (prev == -1){\r\n        prev = 1;\r\n        return 1;\r\n      }\r\n      \r\n    }\r\n    return 0;\r\n  }\r\n  \r\n\r\n/**\r\n * Used by the drawHeatMapValues method to draw heatmap points on to\r\n * the canvas\r\n */\r\nfunction drawPoints(ctx, points, radius, color) {\r\n  const data = points.buffer().values;\r\n\r\n  for (let i = 0; i < data.length; i += 2) {\r\n    const pointY = data[i];\r\n    const pointX = data[i + 1];\r\n\r\n    if (pointX !== 0 && pointY !== 0) {\r\n      ctx.beginPath();\r\n      ctx.arc(pointX, pointY, radius, 0, 2 * Math.PI);\r\n      ctx.fillStyle = color;\r\n      ctx.fill();\r\n    }\r\n  }\r\n}\r\n","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\pages\\Record\\history.js",[],"C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\pages\\Record\\DemoRecord.js",["79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99"],"import * as posenet from '@tensorflow-models/posenet';\r\nimport React, { useRef } from \"react\";\r\n\r\nimport dat from 'dat.gui';\r\nimport FPSStats from 'react-fps-stats';\r\n\r\nimport {drawBoundingBox, drawKeypoints, drawSkeleton, isMobile, toggleLoadingUI, global_zero} from './utils';\r\nfunction DemoRecord(){\r\nconst videoWidth = 600;\r\nconst videoHeight = 500;\r\nvar rep_count = 0;\r\nvar wko_started = 0;\r\nvar done = 0;\r\nvar timer = 0;\r\nvar t0 = 0;\r\nvar count_down = 0;\r\nvar act_dur = 0;\r\nvar last_rep = 0;\r\nconst stats = new FPSStats();\r\n\r\n/**\r\n * Loads a the camera to be used in the demo\r\n *\r\n */\r\nasync function setupCamera() {\r\n  if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\r\n    throw new Error(\r\n        'Browser API navigator.mediaDevices.getUserMedia not available');\r\n  }\r\n\r\n  const video = document.getElementById('video');\r\n  video.width = videoWidth;\r\n  video.height = videoHeight;\r\n\r\n  const mobile = isMobile();\r\n  const stream = await navigator.mediaDevices.getUserMedia({\r\n    'audio': false,\r\n    'video': {\r\n      facingMode: 'user',\r\n      width: mobile ? undefined : videoWidth,\r\n      height: mobile ? undefined : videoHeight,\r\n    },\r\n  });\r\n  video.srcObject = stream;\r\n\r\n  return new Promise((resolve) => {\r\n    video.onloadedmetadata = () => {\r\n      resolve(video);\r\n    };\r\n  });\r\n}\r\n\r\nasync function loadVideo() {\r\n  const video = await setupCamera();\r\n  video.play();\r\n\r\n  return video;\r\n}\r\n\r\nconst defaultQuantBytes = 2;\r\n\r\nconst defaultMobileNetMultiplier = isMobile() ? 0.50 : 0.75;\r\nconst defaultMobileNetStride = 16;\r\nconst defaultMobileNetInputResolution = 500;\r\n\r\nconst guiState = {\r\n  algorithm: 'multi-pose',\r\n  input: {\r\n    architecture: 'MobileNetV1',\r\n    outputStride: defaultMobileNetStride,\r\n    inputResolution: defaultMobileNetInputResolution,\r\n    multiplier: defaultMobileNetMultiplier,\r\n    quantBytes: defaultQuantBytes\r\n  },\r\n  activity: {\r\n    Activity: 'Weight Lifting',\r\n    Repetitions: 10,\r\n    Duration_min: 60\r\n  },\r\n  singlePoseDetection: {\r\n    minPoseConfidence: 0.1,\r\n    minPartConfidence: 0.5,\r\n  },\r\n  multiPoseDetection: {\r\n    maxPoseDetections: 5,\r\n    minPoseConfidence: 0.15,\r\n    minPartConfidence: 0.1,\r\n    nmsRadius: 30.0,\r\n  },\r\n  output: {\r\n    showVideo: true,\r\n    showSkeleton: true,\r\n    showPoints: true,\r\n    showBoundingBox: false,\r\n  },\r\n  net: null,\r\n};\r\n\r\n/**\r\n * Sets up dat.gui controller on the top-right of the window\r\n */\r\nfunction setupGui(cameras, net) {\r\n  guiState.net = net;\r\n\r\n  if (cameras.length > 0) {\r\n    guiState.camera = cameras[0].deviceId;\r\n  }\r\n\r\n  const gui = new dat.GUI({width: 300});\r\n\r\n\r\n  let architectureController = null;\r\n  // guiState[tryResNetButtonName] = function() {\r\n  //   architectureController.setValue('ResNet50')\r\n  // };\r\n  //gui.add(guiState, tryResNetButtonName).name(tryResNetButtonText);\r\n  //updateTryResNetButtonDatGuiCss();\r\n\r\n  // The single-pose algorithm is faster and simpler but requires only one\r\n  // person to be in the frame or results will be innaccurate. Multi-pose works\r\n  // for more than 1 person\r\n  const algorithmController =\r\n      gui.add(guiState, 'algorithm', ['single-pose', 'multi-pose']);\r\n\r\n  // The input parameters have the most effect on accuracy and speed of the\r\n  // network\r\n\r\n  let activityController = null;\r\n\r\n  let activity = gui.addFolder('Workout');\r\n  activityController =\r\n      activity.add(guiState.activity, 'Activity', ['Weight Lifting', 'Jumping jack']);\r\n  guiState.atividade = guiState.activity.activity;\r\n  activity.add(guiState.activity, 'Repetitions', 0, 50);\r\n  activity.add(guiState.activity, 'Duration_min', 0, 180).name('Duration (sec)');\r\n  var obj = { add:function(){ \r\n    console.log(\"clicked\");  \r\n    rep_count = 0;\r\n    count_down = 0;\r\n    wko_started = 1\r\n    done = 0\r\n    global_zero();\r\n    \r\n  }};\r\n\r\n  activity.add(obj,'add').name('Start Workout');\r\n  activity.open();\r\n\r\n  let single = gui.addFolder('Single Pose Detection');\r\n  single.add(guiState.singlePoseDetection, 'minPoseConfidence', 0.0, 1.0);\r\n  single.add(guiState.singlePoseDetection, 'minPartConfidence', 0.0, 1.0);\r\n\r\n  let multi = gui.addFolder('Multi Pose Detection');\r\n  multi.add(guiState.multiPoseDetection, 'maxPoseDetections')\r\n      .min(1)\r\n      .max(20)\r\n      .step(1);\r\n  multi.add(guiState.multiPoseDetection, 'minPoseConfidence', 0.0, 1.0);\r\n  multi.add(guiState.multiPoseDetection, 'minPartConfidence', 0.0, 1.0);\r\n  // nms Radius: controls the minimum distance between poses that are returned\r\n  // defaults to 20, which is probably fine for most use cases\r\n  multi.add(guiState.multiPoseDetection, 'nmsRadius').min(0.0).max(40.0);\r\n  multi.open();\r\n\r\n  let output = gui.addFolder('Output');\r\n  output.add(guiState.output, 'showVideo');\r\n  output.add(guiState.output, 'showSkeleton');\r\n  output.add(guiState.output, 'showPoints');\r\n  output.add(guiState.output, 'showBoundingBox');\r\n  output.open();\r\n\r\n\r\n  algorithmController.onChange(function(value) {\r\n    switch (guiState.algorithm) {\r\n      case 'single-pose':\r\n        multi.close();\r\n        single.open();\r\n        break;\r\n      case 'multi-pose':\r\n        single.close();\r\n        multi.open();\r\n        break;\r\n    }\r\n  });\r\n}\r\n\r\n/**\r\n * Sets up a frames per second panel on the top-left of the window\r\n */\r\nfunction setupFPS() {\r\n  stats.showPanel(0);  // 0: fps, 1: ms, 2: mb, 3+: custom\r\n  document.getElementById('main').appendChild(stats.dom);\r\n}\r\n\r\n/**\r\n * Feeds an image to posenet to estimate poses - this is where the magic\r\n * happens. This function loops with a requestAnimationFrame method.\r\n */\r\nfunction detectPoseInRealTime(video, net) {\r\n  const canvas = document.getElementById('output');\r\n  const ctx = canvas.getContext('2d');\r\n\r\n  // since images are being fed from a webcam, we want to feed in the\r\n  // original image and then just flip the keypoints' x coordinates. If instead\r\n  // we flip the image, then correcting left-right keypoint pairs requires a\r\n  // permutation on all the keypoints.\r\n  const flipPoseHorizontal = true;\r\n\r\n  canvas.width = videoWidth;\r\n  canvas.height = videoHeight;\r\n\r\n  async function poseDetectionFrame() {\r\n    if (guiState.changeToArchitecture) {\r\n      // Important to purge variables and free up GPU memory\r\n      guiState.net.dispose();\r\n      toggleLoadingUI(true);\r\n      guiState.net = await posenet.load({\r\n        architecture: guiState.changeToArchitecture,\r\n        outputStride: guiState.outputStride,\r\n        inputResolution: guiState.inputResolution,\r\n        multiplier: guiState.multiplier,\r\n      });\r\n      toggleLoadingUI(false);\r\n      guiState.architecture = guiState.changeToArchitecture;\r\n      guiState.changeToArchitecture = null;\r\n    }\r\n\r\n    if (guiState.changeToMultiplier) {\r\n      guiState.net.dispose();\r\n      toggleLoadingUI(true);\r\n      guiState.net = await posenet.load({\r\n        architecture: guiState.architecture,\r\n        outputStride: guiState.outputStride,\r\n        inputResolution: guiState.inputResolution,\r\n        multiplier: +guiState.changeToMultiplier,\r\n        quantBytes: guiState.quantBytes\r\n      });\r\n      toggleLoadingUI(false);\r\n      guiState.multiplier = +guiState.changeToMultiplier;\r\n      guiState.changeToMultiplier = null;\r\n    }\r\n\r\n    if (guiState.changeToOutputStride) {\r\n      // Important to purge variables and free up GPU memory\r\n      guiState.net.dispose();\r\n      toggleLoadingUI(true);\r\n      guiState.net = await posenet.load({\r\n        architecture: guiState.architecture,\r\n        outputStride: +guiState.changeToOutputStride,\r\n        inputResolution: guiState.inputResolution,\r\n        multiplier: guiState.multiplier,\r\n        quantBytes: guiState.quantBytes\r\n      });\r\n      toggleLoadingUI(false);\r\n      guiState.outputStride = +guiState.changeToOutputStride;\r\n      guiState.changeToOutputStride = null;\r\n    }\r\n\r\n    if (guiState.changeToInputResolution) {\r\n      // Important to purge variables and free up GPU memory\r\n      guiState.net.dispose();\r\n      toggleLoadingUI(true);\r\n      guiState.net = await posenet.load({\r\n        architecture: guiState.architecture,\r\n        outputStride: guiState.outputStride,\r\n        inputResolution: +guiState.changeToInputResolution,\r\n        multiplier: guiState.multiplier,\r\n        quantBytes: guiState.quantBytes\r\n      });\r\n      toggleLoadingUI(false);\r\n      guiState.inputResolution = +guiState.changeToInputResolution;\r\n      guiState.changeToInputResolution = null;\r\n    }\r\n\r\n    if (guiState.changeToQuantBytes) {\r\n      // Important to purge variables and free up GPU memory\r\n      guiState.net.dispose();\r\n      toggleLoadingUI(true);\r\n      guiState.net = await posenet.load({\r\n        architecture: guiState.architecture,\r\n        outputStride: guiState.outputStride,\r\n        inputResolution: guiState.inputResolution,\r\n        multiplier: guiState.multiplier,\r\n        quantBytes: guiState.changeToQuantBytes\r\n      });\r\n      toggleLoadingUI(false);\r\n      guiState.quantBytes = guiState.changeToQuantBytes;\r\n      guiState.changeToQuantBytes = null;\r\n    }\r\n\r\n    // Begin monitoring code for frames per second\r\n    stats.begin();\r\n\r\n    let poses = [];\r\n    let minPoseConfidence;\r\n    let minPartConfidence;\r\n    switch (guiState.algorithm) {\r\n      case 'single-pose':\r\n        const pose = await guiState.net.estimatePoses(video, {\r\n          flipHorizontal: flipPoseHorizontal,\r\n          decodingMethod: 'single-person'\r\n        });\r\n        poses = poses.concat(pose);\r\n        minPoseConfidence = +guiState.singlePoseDetection.minPoseConfidence;\r\n        minPartConfidence = +guiState.singlePoseDetection.minPartConfidence;\r\n        break;\r\n      case 'multi-pose':\r\n        let all_poses = await guiState.net.estimatePoses(video, {\r\n          flipHorizontal: flipPoseHorizontal,\r\n          decodingMethod: 'multi-person',\r\n          maxDetections: guiState.multiPoseDetection.maxPoseDetections,\r\n          scoreThreshold: guiState.multiPoseDetection.minPartConfidence,\r\n          nmsRadius: guiState.multiPoseDetection.nmsRadius\r\n        });\r\n\r\n        poses = poses.concat(all_poses);\r\n        minPoseConfidence = +guiState.multiPoseDetection.minPoseConfidence;\r\n        minPartConfidence = +guiState.multiPoseDetection.minPartConfidence;\r\n        break;\r\n    }\r\n\r\n    ctx.clearRect(0, 0, videoWidth, videoHeight);\r\n\r\n    if (guiState.output.showVideo) {\r\n      ctx.save();\r\n      ctx.scale(-1, 1);\r\n      ctx.translate(-videoWidth, 0);\r\n      ctx.drawImage(video, 0, 0, videoWidth, videoHeight);\r\n      ctx.restore();\r\n    }\r\n\r\n    // For each pose (i.e. person) detected in an image, loop through the poses\r\n    // and draw the resulting skeleton and keypoints if over certain confidence\r\n    // scores\r\n    poses.forEach(({score, keypoints}) => {\r\n      if (score >= minPoseConfidence) {\r\n        if (guiState.output.showPoints) {\r\n          //console.log(guiState.activity.Repetitions);\r\n          console.log('Repetitions: ', rep_count);\r\n          rep_count = rep_count + drawKeypoints(keypoints, minPartConfidence, ctx, \r\n            rep_count, wko_started, guiState.activity.Activity);\r\n\r\n          if (wko_started == 1 && done == 0){\r\n            ctx.font = \"25px Arial\"; \r\n            ctx.fillText('Repetitions: ' + Math.round(rep_count/2), 10, 90,);\r\n            ctx.fillText(guiState.activity.Activity + ' workout has started', 100, 490,);\r\n            if (timer == 0){\r\n              if (count_down == 0){\r\n                t0 = new Date() / 1000;\r\n                count_down = 1;\r\n              }\r\n              \r\n              ctx.font = \"100px Arial\"; \r\n              var now = new Date() / 1000;\r\n              if (now - t0 <= 5){\r\n                ctx.fillText(5 - Math.round(now - t0), 250, 250,);\r\n                now = new Date() / 1000;\r\n              }\r\n              else{\r\n                timer = 1;\r\n                t0 = new Date() / 1000;\r\n                rep_count = 0;\r\n              }\r\n              \r\n            }\r\n            else{\r\n              act_dur = Math.round(new Date() / 1000 - t0)\r\n              // console.log(new Date() / 1000)\r\n              console.log(\"Actual duration: \", act_dur);\r\n              console.log(\"guiState duration: \", guiState.activity.Duration_min);\r\n              console.log(\"Equal? \", act_dur == guiState.activity.Duration_min);\r\n              \r\n              ctx.fillText('Duration: ' + act_dur + 's', 430, 90,);\r\n              \r\n              if (guiState.activity.Activity == 'Weight Lifting' && Math.round(rep_count/2) == guiState.activity.Repetitions){\r\n                done = 1\r\n              }\r\n              else if (guiState.activity.Activity == 'Jumping jack' && act_dur == guiState.activity.Duration_min){\r\n                done = 1\r\n              }\r\n            }\r\n          }\r\n          else if(done == 1) {\r\n            if (wko_started == 1){\r\n              last_rep = rep_count;\r\n            }\r\n            wko_started = 0;\r\n            ctx.font = \"45px Arial\"; \r\n            ctx.fillStyle = \"green\";\r\n            ctx.fillText('DONE!!', 210, 250,);\r\n            if (guiState.activity.Activity == 'Weight Lifting'){\r\n              ctx.fillText('Duration: ' + act_dur + 's', 160, 300,);\r\n              rep_count = 0;\r\n              global_zero();\r\n            }\r\n            else if (guiState.activity.Activity == 'Jumping jack'){\r\n              ctx.fillText('Repetitions: ' + Math.round(last_rep/2), 160, 300,);\r\n              rep_count = 0;\r\n              global_zero();\r\n            }\r\n            timer = 0;\r\n          }\r\n          else if (rep_count != guiState.activity.Repetitions || done == 0){\r\n            wko_started = 0;\r\n            rep_count = 0;\r\n            global_zero();\r\n            ctx.font = \"29px Arial\"; \r\n            ctx.fillText('Workout not started, plase start a new train...', 10, 30,);\r\n          }\r\n          \r\n          \r\n\r\n        }\r\n        if (guiState.output.showSkeleton) {\r\n          drawSkeleton(keypoints, minPartConfidence, ctx);\r\n        }\r\n        if (guiState.output.showBoundingBox) {\r\n          drawBoundingBox(keypoints, ctx);\r\n        }\r\n      }\r\n    });\r\n\r\n    // End monitoring code for frames per second\r\n    stats.end();\r\n\r\n    requestAnimationFrame(poseDetectionFrame);\r\n  }\r\n\r\n  poseDetectionFrame();\r\n}\r\n\r\n/**\r\n * Kicks off the demo by loading the posenet model, finding and loading\r\n * available camera devices, and setting off the detectPoseInRealTime function.\r\n */\r\nasync function bindPage() {\r\n  toggleLoadingUI(true);\r\n  const net = await posenet.load({\r\n    architecture: guiState.input.architecture,\r\n    outputStride: guiState.input.outputStride,\r\n    inputResolution: guiState.input.inputResolution,\r\n    multiplier: guiState.input.multiplier,\r\n    quantBytes: guiState.input.quantBytes\r\n  });\r\n  toggleLoadingUI(false);\r\n\r\n  let video;\r\n\r\n  try {\r\n    video = await loadVideo();\r\n  } catch (e) {\r\n    let info = document.getElementById('info');\r\n    info.textContent = 'this browser does not support video capture,' +\r\n        'or this device does not have a camera';\r\n    info.style.display = 'block';\r\n    throw e;\r\n  }\r\n\r\n  setupGui([], net);\r\n  //setupFPS();\r\n  detectPoseInRealTime(video, net);\r\n}\r\n\r\nnavigator.getUserMedia = navigator.getUserMedia ||\r\n    navigator.webkitGetUserMedia || navigator.mozGetUserMedia;\r\n// kick off the demo\r\nbindPage();\r\n\r\n  return (\r\n    <div className=\"App\">\r\n      \r\n    </div>\r\n  );\r\n}\r\n\r\nexport default DemoRecord;","C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\components\\VideoSelector.js",[],"C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\components\\poseUtils.js",["100"],"C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\components\\Video.js",[],"C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\components\\demo_util.js",[],"C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\dataset\\index.js",[],"C:\\Users\\ifels\\Documents\\GitHub\\HackDavis-2021\\my-app\\src\\MoreRecord.js",[],{"ruleId":"101","severity":1,"message":"102","line":1,"column":8,"nodeType":"103","messageId":"104","endLine":1,"endColumn":12},{"ruleId":"101","severity":1,"message":"105","line":5,"column":3,"nodeType":"103","messageId":"104","endLine":5,"endColumn":9},{"ruleId":"101","severity":1,"message":"106","line":7,"column":3,"nodeType":"103","messageId":"104","endLine":7,"endColumn":7},{"ruleId":"101","severity":1,"message":"107","line":8,"column":3,"nodeType":"103","messageId":"104","endLine":8,"endColumn":16},{"ruleId":"101","severity":1,"message":"108","line":9,"column":3,"nodeType":"103","messageId":"104","endLine":9,"endColumn":12},{"ruleId":"101","severity":1,"message":"109","line":11,"column":8,"nodeType":"103","messageId":"104","endLine":11,"endColumn":14},{"ruleId":"101","severity":1,"message":"110","line":12,"column":17,"nodeType":"103","messageId":"104","endLine":12,"endColumn":23},{"ruleId":"101","severity":1,"message":"111","line":13,"column":13,"nodeType":"103","messageId":"104","endLine":13,"endColumn":15},{"ruleId":"101","severity":1,"message":"112","line":14,"column":13,"nodeType":"103","messageId":"104","endLine":14,"endColumn":20},{"ruleId":"101","severity":1,"message":"113","line":15,"column":8,"nodeType":"103","messageId":"104","endLine":15,"endColumn":14},{"ruleId":"101","severity":1,"message":"114","line":1,"column":25,"nodeType":"103","messageId":"104","endLine":1,"endColumn":34},{"ruleId":"101","severity":1,"message":"111","line":3,"column":13,"nodeType":"103","messageId":"104","endLine":3,"endColumn":15},{"ruleId":"101","severity":1,"message":"115","line":12,"column":8,"nodeType":"103","messageId":"104","endLine":12,"endColumn":27},{"ruleId":"116","replacedBy":"117"},{"ruleId":"118","replacedBy":"119"},{"ruleId":"120","severity":1,"message":"121","line":46,"column":14,"nodeType":"122","messageId":"123","endLine":46,"endColumn":16},{"ruleId":"120","severity":1,"message":"121","line":210,"column":50,"nodeType":"122","messageId":"123","endLine":210,"endColumn":52},{"ruleId":"120","severity":1,"message":"121","line":221,"column":18,"nodeType":"122","messageId":"123","endLine":221,"endColumn":20},{"ruleId":"120","severity":1,"message":"121","line":225,"column":23,"nodeType":"122","messageId":"123","endLine":225,"endColumn":25},{"ruleId":"120","severity":1,"message":"121","line":230,"column":21,"nodeType":"122","messageId":"123","endLine":230,"endColumn":23},{"ruleId":"101","severity":1,"message":"110","line":2,"column":17,"nodeType":"103","messageId":"104","endLine":2,"endColumn":23},{"ruleId":"101","severity":1,"message":"124","line":112,"column":7,"nodeType":"103","messageId":"104","endLine":112,"endColumn":29},{"ruleId":"101","severity":1,"message":"125","line":131,"column":3,"nodeType":"103","messageId":"104","endLine":131,"endColumn":21},{"ruleId":"126","severity":1,"message":"127","line":174,"column":5,"nodeType":"128","messageId":"129","endLine":183,"endColumn":6},{"ruleId":"101","severity":1,"message":"130","line":190,"column":10,"nodeType":"103","messageId":"104","endLine":190,"endColumn":18},{"ruleId":"126","severity":1,"message":"127","line":297,"column":5,"nodeType":"128","messageId":"129","endLine":320,"endColumn":6},{"ruleId":"120","severity":1,"message":"121","line":343,"column":27,"nodeType":"122","messageId":"123","endLine":343,"endColumn":29},{"ruleId":"120","severity":1,"message":"121","line":343,"column":40,"nodeType":"122","messageId":"123","endLine":343,"endColumn":42},{"ruleId":"120","severity":1,"message":"121","line":347,"column":23,"nodeType":"122","messageId":"123","endLine":347,"endColumn":25},{"ruleId":"120","severity":1,"message":"121","line":348,"column":30,"nodeType":"122","messageId":"123","endLine":348,"endColumn":32},{"ruleId":"120","severity":1,"message":"121","line":371,"column":46,"nodeType":"122","messageId":"123","endLine":371,"endColumn":48},{"ruleId":"120","severity":1,"message":"121","line":375,"column":46,"nodeType":"122","messageId":"123","endLine":375,"endColumn":48},{"ruleId":"120","severity":1,"message":"121","line":375,"column":93,"nodeType":"122","messageId":"123","endLine":375,"endColumn":95},{"ruleId":"120","severity":1,"message":"121","line":378,"column":51,"nodeType":"122","messageId":"123","endLine":378,"endColumn":53},{"ruleId":"120","severity":1,"message":"121","line":378,"column":80,"nodeType":"122","messageId":"123","endLine":378,"endColumn":82},{"ruleId":"120","severity":1,"message":"121","line":383,"column":24,"nodeType":"122","messageId":"123","endLine":383,"endColumn":26},{"ruleId":"120","severity":1,"message":"121","line":384,"column":29,"nodeType":"122","messageId":"123","endLine":384,"endColumn":31},{"ruleId":"120","severity":1,"message":"121","line":391,"column":44,"nodeType":"122","messageId":"123","endLine":391,"endColumn":46},{"ruleId":"120","severity":1,"message":"121","line":396,"column":49,"nodeType":"122","messageId":"123","endLine":396,"endColumn":51},{"ruleId":"120","severity":1,"message":"131","line":403,"column":30,"nodeType":"122","messageId":"123","endLine":403,"endColumn":32},{"ruleId":"120","severity":1,"message":"121","line":403,"column":71,"nodeType":"122","messageId":"123","endLine":403,"endColumn":73},{"ruleId":"101","severity":1,"message":"132","line":58,"column":10,"nodeType":"103","messageId":"104","endLine":58,"endColumn":32},"no-unused-vars","'logo' is defined but never used.","Identifier","unusedVar","'Switch' is defined but never used.","'Link' is defined but never used.","'useRouteMatch' is defined but never used.","'useParams' is defined but never used.","'Record' is defined but never used.","'useRef' is defined but never used.","'tf' is defined but never used.","'bodyPix' is defined but never used.","'Webcam' is defined but never used.","'Component' is defined but never used.","'ReactTimerStopwatch' is defined but never used.","no-native-reassign",["133"],"no-negated-in-lhs",["134"],"eqeqeq","Expected '===' and instead saw '=='.","BinaryExpression","unexpected","'architectureController' is assigned a value but never used.","'activityController' is assigned a value but never used.","default-case","Expected a default case.","SwitchStatement","missingDefaultCase","'setupFPS' is defined but never used.","Expected '!==' and instead saw '!='.","'cosineDistanceMatching' is defined but never used.","no-global-assign","no-unsafe-negation"]